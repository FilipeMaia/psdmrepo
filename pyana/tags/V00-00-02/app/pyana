#!/usr/bin/python2.4
#--------------------------------------------------------------------------
# File and Version Information:
#  $Id$
#
# Description:
#  Script pyxtcreader...
#
#------------------------------------------------------------------------

"""Analysis job.

This software was developed for the LUSI project.  If you use all or 
part of it, please give an appropriate acknowledgement.

@see RelatedModule

@version $Id$ 

@author Andrei Salnikov
"""

#------------------------------
#  Module's version from CVS --
#------------------------------
__version__ = "$Revision$"
# $Source$

#--------------------------------
#  Imports of standard modules --
#--------------------------------
import sys
import os
import logging
from optparse import OptionParser
import multiprocessing as mp
from resource import *

#-----------------------------
# Imports for other modules --
#-----------------------------
from pypdsdata import xtc
from pyana import event
from pyana.histo import HistoMgr
from pyana.input import dgramGen, threadedDgramGen
from pyana.userana import mod_import, evt_dispatch
from pyana.mp_proto import *
from pyana.config import config
from pyana.merger import merger

#---------------------
# Local definitions --
#---------------------

def _rusage(msg, ru1, ru2):
    
    print "%s: %.1f user %.1f sys" % ( msg, ru2.ru_utime-ru1.ru_utime, ru2.ru_stime-ru1.ru_stime )


def _proc(jobname, id, pipe, userObjects, dg_ref):
    """ method which is running in child process when we do multi-processing """

    ru1 = getrusage(RUSAGE_SELF)
    
    # instantiate histo manager (memory-based)
    hmgr = HistoMgr()
    
    # create own environment, make unique job name
    env = event.Env(jobname, hmgr, subproc=True)

    logging.info("proc-%s: starting job %s", id, jobname)

    dispatch = evt_dispatch(userObjects)
    proto = mp_proto(pipe, dg_ref, 'prot-%d' % id)
    nevent = 0

    # event loop
    for req in proto.getRequest():

        # request is a tuple with first element being opcode
        if req[0] == OP_EVENT :

            epics_data = req[1]
            dg = req[2]

            evt = event.Event(dg)
            
            # update configuration objects
            env.updateConfig(evt)
    
            # update epics data
            env.m_epics.m_id2epics = epics_data
    
            # process all data
            dispatch.dispatch(evt, env)
    
            if evt.seq().service() == xtc.TransitionId.L1Accept : nevent += 1

        elif req[0] == OP_FINISH :
            
            logging.info("proc-%s: received FIN", id)
            dispatch.finish(env)
            
        elif req[0] == OP_RESULT :
            
            logging.info("proc-%s: result requested, tag=%s", id, req[1])
            proto.sendData( env.result() )

        elif req[0] == OP_END :
            
            logging.info("proc-%s: received END", id)
            # stop here
            break
            
    # close histo files
    hmgr.close()

    logging.info("proc-%s: processed %d events", id, nevent)

    proto.close()

    ru2 = getrusage(RUSAGE_SELF)
    _rusage( "proc-%s time" % id, ru1, ru2 )

#---------------------------------
#  Application class definition --
#---------------------------------

def main( argv ) :

    ru1 = getrusage(RUSAGE_SELF), getrusage(RUSAGE_CHILDREN)

    parser = OptionParser(usage="%prog [options] [xtc-files ...]")
    parser.set_defaults( verbose = 0, 
                         config = None,
                         file_list = None, 
                         num_events = 0,
                         job_name = None,
                         module = [],
                         num_cpu = 1,
                         dg_ref = False )
    
    parser.add_option( '-v', "--verbose", action="count", help="increase verbosity" )
    parser.add_option( '-c', "--config", metavar="FILE",
                       help="configuration file" )
    parser.add_option( '-l', "--file-list", metavar="FILE",
                       help="file with a list of file names in it" )
    parser.add_option( '-n', "--num-events", metavar="NUMBER", type="int",
                       help="maximum number of events to process" )
    parser.add_option( '-j', "--job-name", metavar="STRING", 
                       help="job name, default is deduced from file name(s)" )
    parser.add_option( '-m', "--module", metavar="NAME", action="append",
                       help="user module name, multiple modules allowed, default is myana" )
    parser.add_option( '-p', "--num-cpu", metavar="NUMBER", type="int",
                       help="number grater than 1 enables multi-processing" )
    parser.add_option( '-r', "--dg-ref", action="store_true",
                       help="pass datagrams by-reference to children processes" )

    (options, args) = parser.parse_args()
    
    # set logging level
    log_levels = { 0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG }
    level = log_levels.get ( options.verbose, logging.DEBUG )
    logging.basicConfig( level=level )

    # read config file
    try :
        jobConfig = config(options.config)
    except Exception, exc:
        logging.error("config error: %s", exc)
        return 2

    # get file names
    if not args and not options.file_list :
        parser.error("at least one file name or a file list required")
    if args and options.file_list :
        parser.error("file list cannot be used with the file names")
    if options.file_list :
        # read file names from file
        names = file(options.file_list).readlines()
        names = [ n.strip() for n in names ]
        names = [ n for n in names if n ]
    else :
        names = args

    # get job name
    if options.job_name :
        jobname = options.job_name
    else :
        if options.file_list :
            jobname = os.path.basename(options.file_list)
            jobname = os.path.splitext(jobname)[0]
        else :
            jobname = os.path.basename(names[0])
            jobname = os.path.splitext(jobname)[0]

    # get all names of user modules
    modules = options.module
    if not modules :
        try:
            modules = jobConfig.getJobConfig("modules")
            if modules : modules = modules.split()
        except Exception, e :
            logging.error("config error: %s", exc)
            return 2
    if not modules :
        logging.error("no user modules defined")
        return 2
    
    # import all user modules, mod_import does not throw but returns None instead
    modConfig = map(jobConfig.getModuleConfig, modules)
    userObjects = map(mod_import, modules, modConfig)
    if None in userObjects :
        # not all modules imported 
        return 2

    # start worker process if requested
    pipes = []
    procs = []
    for proc in range(max(options.num_cpu-1,0)) :
        parent_conn, child_conn = mp.Pipe()
        pipes.append(mp_proto(parent_conn, options.dg_ref, 'prot-main'))
        procs.append(mp.Process(target=_proc, args=(jobname, proc, child_conn, userObjects, options.dg_ref)))
    for p in procs : p.start()

    # instantiate histo manager
    hmgr = HistoMgr( file=jobname+".root" )

    # create environment
    env = event.Env(jobname, hmgr)

    dispatch = evt_dispatch(userObjects)
    nevent = 0
    ndamage = 0
    damagemask = 0
    next = 0

    # read datagrams one by one
    for dgtup in dgramGen( names ) :

        dg, fileName, fpos = dgtup

        damage = dg.xtc.damage.value()
        svc = dg.seq.service()

        if damage :
            ndamage += 1
            damagemask |= damage

        if not damage or svc == xtc.TransitionId.Configure:
            
            evt = event.Event(dg)
            
            # update environment
            env.update ( evt )

            if procs:
                
                # pass all the data to children
                if svc == xtc.TransitionId.Configure :
                    # each configure transitions goes to each child
                    for p in pipes : p.sendEventData(dgtup, env)
                elif svc == xtc.TransitionId.L1Accept :
                    # event data goes to next child
                    p = pipes[next]
                    next = (next+1) % len(pipes)
                    p.sendEventData(dgtup, env)

            else :
                
                # process all data
                dispatch.dispatch(evt, env)
                
        if svc == xtc.TransitionId.L1Accept :
            nevent += 1

        #print "Processed %d events, %d damaged, with damage mask %#x" % (nevent, ndamage, damagemask)
        
        if options.num_events and nevent >= options.num_events :
            logging.info("event limit reached (%d), terminating", nevent)
            break

    # finish
    dispatch.finish(env)

    # send FIN to all processes
    for p in pipes : 
        p.sendCode(OP_FINISH)

    # get results from all processes
    merge = merger() 
    for p in pipes : 
        merge.merge(p.getResult())
    merge.finish(env)    

    # send END to all processes
    for p in pipes :
        p.sendCode(OP_END)

    # wait for all processes
    for p in pipes : p.close()
    for p in procs : p.join()

    # close histo file
    hmgr.close()

    logging.info("Processed %d events, %d damaged, with damage mask %#x", nevent, ndamage, damagemask)

    ru2 = getrusage(RUSAGE_SELF), getrusage(RUSAGE_CHILDREN)
    _rusage( "self  time", ru1[0], ru2[0] )
    _rusage( "child time", ru1[1], ru2[1] )
    
#
#  run application when imported as a main module
#
if __name__ == "__main__" :
    sys.path.insert(0, ".")
    sys.exit( main(sys.argv) )
